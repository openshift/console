{
  "Troubleshoot": "Troubleshoot",
  "Add Capacity": "Add Capacity",
  "Object Buckets": "Object Buckets",
  "Object Bucket Claims": "Object Bucket Claims",
  "Overview": "Overview",
  "Use existing claim": "Use existing claim",
  "Select claim": "Select claim",
  "Create new claim": "Create new claim",
  "Create": "Create",
  "Cancel": "Cancel",
  "{{replica}} Replication": "{{replica}} Replication",
  "Pool name": "Pool name",
  "my-block-pool": "my-block-pool",
  "pool-name-help": "pool-name-help",
  "Data protection policy": "Data protection policy",
  "Select replication": "Select replication",
  "Volume type": "Volume type",
  "Select volume type": "Select volume type",
  "Compression": "Compression",
  "Enable compression": "Enable compression",
  "Enabling compression may result in little or no space savings for encrypted or random data. Also, enabling compression may have an impact on I/O performance.": "Enabling compression may result in little or no space savings for encrypted or random data. Also, enabling compression may have an impact on I/O performance.",
  "The OpenShift Storage cluster is not available. Try again after the storage cluster is ready to use.": "The OpenShift Storage cluster is not available. Try again after the storage cluster is ready to use.",
  "Create Block Pool": "Create Block Pool",
  "Close": "Close",
  "Pool creation is not supported for openshift container storage external mode.": "Pool creation is not supported for openshift container storage external mode.",
  "A block pool is a logical entity providing elastic capacity to applications and workloads. Pools provide a means of supporting policies for access data resilience and storage efficiency.": "A block pool is a logical entity providing elastic capacity to applications and workloads. Pools provide a means of supporting policies for access data resilience and storage efficiency.",
  "Block Pool Creation Form": "Block Pool Creation Form",
  "Name": "Name",
  "Bucket Name": "Bucket Name",
  "Type": "Type",
  "Region": "Region",
  "BackingStore Table": "BackingStore Table",
  "Each BackingStore can be used for one tier at a time. Selecting a BackingStore in one tier will remove the resource from the second tier option and vice versa.": "Each BackingStore can be used for one tier at a time. Selecting a BackingStore in one tier will remove the resource from the second tier option and vice versa.",
  "Bucket created for OCS Service": "Bucket created for OCS Service",
  "Tier 1 - BackingStores": "Tier 1 - BackingStores",
  "Create BackingStore ": "Create BackingStore ",
  "Tier-1-Table": "Tier-1-Table",
  "{{bs, number}} BackingStore ": "{{bs, number}} BackingStore ",
  "{{bs, number}} BackingStore _plural": "{{bs, number}} BackingStore s",
  "selected": "selected",
  "Tier 2 - BackingStores": "Tier 2 - BackingStores",
  "Tier-2-Table": "Tier-2-Table",
  "General": "General",
  "Placement Policy": "Placement Policy",
  "Resources": "Resources",
  "Review": "Review",
  "Create BucketClass": "Create BucketClass",
  "Create new BucketClass": "Create new BucketClass",
  "BucketClass is a CRD representing a class for buckets that defines tiering policies and data placements for an OBC.": "BucketClass is a CRD representing a class for buckets that defines tiering policies and data placements for an OBC.",
  "Edit BucketClass Resource": "Edit BucketClass Resource",
  "{{storeType}} represents a storage target to be used as the underlying storage for the data in Multicloud Object Gateway buckets.": "{{storeType}} represents a storage target to be used as the underlying storage for the data in Multicloud Object Gateway buckets.",
  "Cancel ": "Cancel ",
  "Save": "Save",
  "What is a BackingStore ?": "What is a BackingStore ?",
  "BackingStore represents a storage target to be used as the underlying storage for the data in Multicloud Object Gateway buckets.": "BackingStore represents a storage target to be used as the underlying storage for the data in Multicloud Object Gateway buckets.",
  "Multiple types of BackingStores are supported: asws-s3 s3-compatible google-cloud-storage azure-blob obc PVC.": "Multiple types of BackingStores are supported: asws-s3 s3-compatible google-cloud-storage azure-blob obc PVC.",
  "Learn More": "Learn More",
  "What is a BucketClass?": "What is a BucketClass?",
  "A set of policies which would apply to all buckets (OBCs) created with the specific bucket class. These policies include placement, namespace and caching": "A set of policies which would apply to all buckets (OBCs) created with the specific bucket class. These policies include placement, namespace and caching",
  "BucketClass type": "BucketClass type",
  "3-63 chars": "3-63 chars",
  "Starts and ends with lowercase number or letter": "Starts and ends with lowercase number or letter",
  "Only lowercase letters, numbers, non-consecutive periods or hyphens": "Only lowercase letters, numbers, non-consecutive periods or hyphens",
  "Avoid using the form of an IP address": "Avoid using the form of an IP address",
  "Globally unique name": "Globally unique name",
  "BucketClass name": "BucketClass name",
  "A unique name for the bucket class within the project.": "A unique name for the bucket class within the project.",
  "my-multi-cloud-mirror": "my-multi-cloud-mirror",
  "BucketClass Name": "BucketClass Name",
  "Description (Optional)": "Description (Optional)",
  "Description of bucket class": "Description of bucket class",
  "What is a Namespace Policy?": "What is a Namespace Policy?",
  "Namespace policy can be set to one single read and write source, multi read sources or cached policy.": "Namespace policy can be set to one single read and write source, multi read sources or cached policy.",
  "Namespace Policy Type": "Namespace Policy Type",
  "What is Caching?": "What is Caching?",
  "Caching is a policy that creates local copies of the data. It saves the copies locally to improve performance for frequently accessed data. Each cached copy has a TTL and is verified against the hub. Each non-read operation(upload, overwrite, delete) is performed on the hub": "Caching is a policy that creates local copies of the data. It saves the copies locally to improve performance for frequently accessed data. Each cached copy has a TTL and is verified against the hub. Each non-read operation(upload, overwrite, delete) is performed on the hub",
  "Hub namespace store ": "Hub namespace store ",
  "A single namespace-store, defines the read and write target of the namespace bucket": "A single namespace-store, defines the read and write target of the namespace bucket",
  "NamespaceStore": "NamespaceStore",
  "Cache data settings": "Cache data settings",
  "The data will be temporarily copied on a backing store in order to later access it much more quickly.": "The data will be temporarily copied on a backing store in order to later access it much more quickly.",
  "Backing store": "Backing store",
  "a local backing store is recommended for better performance": "a local backing store is recommended for better performance",
  "Time to live": "Time to live",
  "Time to live is the time that an object is stored in a caching system before it is deleted or refreshed. Default: 1 hr, Min: 15 mins, Max: 24 hrs": "Time to live is the time that an object is stored in a caching system before it is deleted or refreshed. Default: 1 hr, Min: 15 mins, Max: 24 hrs",
  "Read NamespaceStores": "Read NamespaceStores",
  "Select list of namespace stores, defines the read targets of the namespace bucket": "Select list of namespace stores, defines the read targets of the namespace bucket",
  "Create NamespaceStore": "Create NamespaceStore",
  "{{nns, number}} namespace store ": "{{nns, number}} namespace store",
  "{{nns, number}} namespace store _plural": "{{nns, number}} namespace stores",
  " selected": " selected",
  "Write NamespaceStore": "Write NamespaceStore",
  "Select a single namespace store, defines the write target of the namespace bucket": "Select a single namespace store, defines the write target of the namespace bucket",
  "Read and Write NamespaceStore ": "Read and Write NamespaceStore ",
  "Select one namespace-store, defines the read and write targets of the namespace bucket": "Select one namespace-store, defines the read and write targets of the namespace bucket",
  "What is a Placement Policy?": "What is a Placement Policy?",
  "Data placement capabilities are built as a multi-layer structure here are the layers bottom-up:": "Data placement capabilities are built as a multi-layer structure here are the layers bottom-up:",
  "Spread Tier - list of BackingStores aggregates the storage of multiple stores.": "Spread Tier - list of BackingStores aggregates the storage of multiple stores.",
  "Mirroring Tier - list of spread-layers async-mirroring to all mirrors with locality optimization (will allocate on the closest region to the source endpoint) mirroring requires at least two BackingStores.": "Mirroring Tier - list of spread-layers async-mirroring to all mirrors with locality optimization (will allocate on the closest region to the source endpoint) mirroring requires at least two BackingStores.",
  "The number of replicas can be configured via the NooBaa management console.": "The number of replicas can be configured via the NooBaa management console.",
  "Tier 1 - Policy Type": "Tier 1 - Policy Type",
  "Spread": "Spread",
  "Spreading the data across the chosen resources. By default a replica of one copy is used and does not include failure tolerance in case of resource failure.": "Spreading the data across the chosen resources. By default a replica of one copy is used and does not include failure tolerance in case of resource failure.",
  "Mirror": "Mirror",
  "Full duplication of the data in each chosen resource By default a replica of one copy per location is used. includes failure tolerance in case of resource failure.": "Full duplication of the data in each chosen resource By default a replica of one copy per location is used. includes failure tolerance in case of resource failure.",
  "Add Tier": "Add Tier",
  "Tier 2 - Policy type": "Tier 2 - Policy type",
  "Remove Tier": "Remove Tier",
  "Spreading the data across the chosen resources does not includes failure tolerance in case of resource failure.": "Spreading the data across the chosen resources does not includes failure tolerance in case of resource failure.",
  "Full duplication of the data in each chosen resource includes failure tolerance in cause of resource failure.": "Full duplication of the data in each chosen resource includes failure tolerance in cause of resource failure.",
  "Namespace Policy: ": "Namespace Policy: ",
  "Read and write NamespaceStore : ": "Read and write NamespaceStore : ",
  "Hub namespace store: ": "Hub namespace store: ",
  "Cache backing store: ": "Cache backing store: ",
  "Time to live: ": "Time to live: ",
  "Resources ": "Resources ",
  "Selected read namespace stores: ": "Selected read namespace stores: ",
  "Selected write namespace store: ": "Selected write namespace store: ",
  "Placement policy details ": "Placement policy details ",
  "Tier 1: ": "Tier 1: ",
  "Selected BackingStores": "Selected BackingStores",
  "Tier 2: ": "Tier 2: ",
  "Review BucketClass": "Review BucketClass",
  "BucketClass type: ": "BucketClass type: ",
  "BucketClass name: ": "BucketClass name: ",
  "Description: ": "Description: ",
  "Provider {{provider}}": "Provider {{provider}}",
  "Create new BackingStore ": "Create new BackingStore ",
  "An error has occured while fetching backing stores": "An error has occured while fetching backing stores",
  "Select a backing store": "Select a backing store",
  "Storage targets that are used to store chunks of data on Multicloud Object Gateway buckets.": "Storage targets that are used to store chunks of data on Multicloud Object Gateway buckets.",
  "A BackingStore represents a storage target to be used as the underlying storage layer in Multicloud Object Gateway buckets.": "A BackingStore  represents a storage target to be used as the underlying storage layer in Multicloud Object Gateway buckets.",
  "Multiple types of BackingStores are supported: AWS S3 S3 Compatible Google Cloud Storage Azure Blob PVC.": "Multiple types of BackingStores are supported: AWS S3 S3 Compatible Google Cloud Storage Azure Blob PVC.",
  "BackingStore Name": "BackingStore Name",
  "A unique name for the BackingStore  within the project": "A unique name for the BackingStore  within the project",
  "Name can contain a max of 43 characters": "Name can contain a max of 43 characters",
  "Provider": "Provider",
  "Create BackingStore": "Create BackingStore",
  "Not available": "Not available",
  "Not enough usage data": "Not enough usage data",
  "used": "used",
  "available": "available",
  "Other": "Other",
  "All other capacity usage that are not a part of the top 5 consumers.": "All other capacity usage that are not a part of the top 5 consumers.",
  "Available": "Available",
  "Rebuilding data resiliency": "Rebuilding data resiliency",
  "{{formattedProgress, number}}%": "{{formattedProgress, number}}%",
  "Activity": "Activity",
  "Estimating {{formattedEta}} to completion": "Estimating {{formattedEta}} to completion",
  "Object": "Object",
  "Object_plural": "Objects",
  "Buckets": "Buckets",
  "The number of buckets managed on Multicloud Object Gateway, Object bucket claims and the object bucket created as a result of object bucket claims on both Multicloud Object Gateway and RGW (if deployed).": "The number of buckets managed on Multicloud Object Gateway, Object bucket claims and the object bucket created as a result of object bucket claims on both Multicloud Object Gateway and RGW (if deployed).",
  "NooBaa Bucket": "NooBaa Bucket",
  "Total": "Total",
  "Projects": "Projects",
  "BucketClasses": "BucketClasses",
  "Service Type": "Service Type",
  "All": "All",
  "Cluster-wide": "Cluster-wide",
  "Any NON Object bucket claims that were created via an S3 client or via the NooBaa UI system.": "Any NON Object bucket claims that were created via an S3 client or via the NooBaa UI system.",
  "Capacity breakdown": "Capacity breakdown",
  "This card shows used capacity for different resources. The available capacity is based on cloud services therefore it cannot be shown.": "This card shows used capacity for different resources. The available capacity is based on cloud services therefore it cannot be shown.",
  "Type: {{serviceType}}": "Type: {{serviceType}}",
  "Service Type Dropdown": "Service Type Dropdown",
  "Service Type Dropdown Toggle": "Service Type Dropdown Toggle",
  "By: {{serviceType}}": "By: {{serviceType}}",
  "Break By Dropdown": "Break By Dropdown",
  "Break by": "Break by",
  "Providers": "Providers",
  "Accounts": "Accounts",
  "Metric": "Metric",
  "I/O Operations": "I/O Operations",
  "Logial Used Capacity": "Logial Used Capacity",
  "Physical vs. Logical used capacity": "Physical vs. Logical used capacity",
  "Egress": "Egress",
  "Latency": "Latency",
  "Bandwidth": "Bandwidth",
  "Type: {{selectedService}}": "Type: {{selectedService}}",
  "{{selectedMetric}} by {{selectedBreakdown}}": "{{selectedMetric}} by {{selectedBreakdown}}",
  "thousands": "thousands",
  "millions": "millions",
  "billions": "billions",
  "Total Reads {{totalRead}}": "Total Reads {{totalRead}}",
  "Total Writes {{totalWrite}}": "Total Writes {{totalWrite}}",
  "Total Logical Used Capacity {{logicalCapacity}}": "Total Logical Used Capacity {{logicalCapacity}}",
  "Total Physical Used Capacity {{physicalcapacity}}": "Total Physical Used Capacity {{physicalcapacity}}",
  "Performance": "Performance",
  "Shows an overview of the data consumption per provider or account collected from the day of the entity creation.": "Shows an overview of the data consumption per provider or account collected from the day of the entity creation.",
  "(in {{suffixLabel}})": "(in {{suffixLabel}})",
  "GET {{GETLatestValue}}": "GET {{GETLatestValue}}",
  "PUT {{PUTLatestValue}}": "PUT {{PUTLatestValue}}",
  "Details": "Details",
  "Service Name": "Service Name",
  "System Name": "System Name",
  "Version": "Version",
  "Resource Providers": "Resource Providers",
  "A list of all Multicloud Object Gateway resources that are currently in use. Those resources are used to store data according to the buckets' policies and can be a cloud-based resource or a bare metal resource.": "A list of all Multicloud Object Gateway resources that are currently in use. Those resources are used to store data according to the buckets' policies and can be a cloud-based resource or a bare metal resource.",
  "Object Service": "Object Service",
  "Data Resiliency": "Data Resiliency",
  "Object Service Status": "Object Service Status",
  "The object service includes 2 services.": "The object service includes 2 services.",
  "The data resiliency includes 2 services": "The data resiliency includes 2 services",
  "Services": "Services",
  "Status": "Status",
  "All resources are unhealthy": "All resources are unhealthy",
  "Object Bucket has an issue": "Object Bucket has an issue",
  "Many buckets have issues": "Many buckets have issues",
  "Some buckets have issues": "Some buckets have issues",
  "{{capacityRatio, number}}:1": "{{capacityRatio, number}}:1",
  "Compression ratio": "Compression ratio",
  "OpenShift Container Storage can be configured to use compression. The efficiency rate reflects the actual compression ratio when using such a configuration.": "OpenShift Container Storage can be configured to use compression. The efficiency rate reflects the actual compression ratio when using such a configuration.",
  "Savings": "Savings",
  "Savings shows the uncompressed and non-deduped data that would have been stored without those techniques.": "Savings shows the uncompressed and non-deduped data that would have been stored without those techniques.",
  "Storage Efficiency": "Storage Efficiency",
  "OpenShift Container Storage Overview": "OpenShift Container Storage Overview",
  "Storage Classes": "Storage Classes",
  "Pods": "Pods",
  "{{metricType}}": "{{metricType}}",
  "Cluster Name": "Cluster Name",
  "Mode": "Mode",
  "OCS Cluster": "OCS Cluster",
  "Utilization": "Utilization",
  "Used Capacity": "Used Capacity",
  "Requested capacity": "Requested capacity",
  "Expanding OCS Cluster": "Expanding OCS Cluster",
  "Upgrading OCS Operator": "Upgrading OCS Operator",
  "Used Capacity Breakdown": "Used Capacity Breakdown",
  "This card shows the used capacity for different Kubernetes resources. The figures shown represent the Usable storage, meaning that data replication is not taken into consideration.": "This card shows the used capacity for different Kubernetes resources. The figures shown represent the Usable storage, meaning that data replication is not taken into consideration.",
  "Inventory": "Inventory",
  "Error": "Error",
  "Warning": "Warning",
  "Raw Capacity": "Raw Capacity",
  "RAW capacity is the absolute total disk space available to the array subsystem.": "RAW capacity is the absolute total disk space available to the array subsystem.",
  "Used": "Used",
  "Available versus Used Capacity": "Available versus Used Capacity",
  "Used of {{capacity}}": "Used of {{capacity}}",
  "Not Available": "Not Available",
  "Progressing": "Progressing",
  "The Compression Ratio represents the compressible data effectiveness metric inclusive of all compression-enabled pools.": "The Compression Ratio represents the compressible data effectiveness metric inclusive of all compression-enabled pools.",
  "The Savings metric represents the actual disk capacity saved inclusive of all compression-enabled pools and associated replicas.": "The Savings metric represents the actual disk capacity saved inclusive of all compression-enabled pools and associated replicas.",
  "Performance metrics over time showing IOPS, Latency and more. Each metric is a link to a detailed view of this metric.": "Performance metrics over time showing IOPS, Latency and more. Each metric is a link to a detailed view of this metric.",
  "IOPS": "IOPS",
  "Throughput": "Throughput",
  "Recovery": "Recovery",
  "Disk State": "Disk State",
  "OCS Status": "OCS Status",
  "Model": "Model",
  "Capacity": "Capacity",
  "Filesystem": "Filesystem",
  "Disks List": "Disks List",
  "Start Disk Replacement": "Start Disk Replacement",
  "<0>{{diskName}}</0> can be replaced with a disk of same type.": "<0>{{diskName}}</0> can be replaced with a disk of same type.",
  "Troubleshoot disk <1>{{diskName}}</1>": "Troubleshoot disk <1>{{diskName}}</1>",
  "here": "here",
  "Online": "Online",
  "Offline": "Offline",
  "NotResponding": "NotResponding",
  "PreparingToReplace": "PreparingToReplace",
  "ReplacementFailed": "ReplacementFailed",
  "ReplacementReady": "ReplacementReady",
  "Unknown": "Unknown",
  "This is a required field": "This is a required field",
  "Please enter a URL": "Please enter a URL",
  "Please enter a valid port": "Please enter a valid port",
  "Key Management Service Provider": "Key Management Service Provider",
  "kms-provider-name": "kms-provider-name",
  "Address": "Address",
  "Port": "Port",
  "Token": "Token",
  "Advanced Settings": "Advanced Settings",
  "No StorageClass selected": "No StorageClass selected",
  "The Arbiter stretch cluster requires a minimum of 4 nodes (2 different zones, 2 nodes per zone). Please choose a different StorageClass or create a new LocalVolumeSet that matches the minimum node requirement.": "The Arbiter stretch cluster requires a minimum of 4 nodes (2 different zones, 2 nodes per zone). Please choose a different StorageClass or create a new LocalVolumeSet that matches the minimum node requirement.",
  "The StorageCluster requires a minimum of 3 nodes. Please choose a different StorageClass or create a new LocalVolumeSet that matches the minimum node requirement.": "The StorageCluster requires a minimum of 3 nodes. Please choose a different StorageClass or create a new LocalVolumeSet that matches the minimum node requirement.",
  "Adding capacity for <1>{{name}}</1>, may increase your expenses.": "Adding capacity for <1>{{name}}</1>, may increase your expenses.",
  "Storage Class": "Storage Class",
  "x {{ replica, number }} replicas =": "x {{ replica, number }} replicas =",
  "Add": "Add",
  "Vault enterprise namespaces are isolated environments that functionally exist as Vaults within a Vault. They have separate login paths and support creating and managing data isolated to their namespace.": "Vault enterprise namespaces are isolated environments that functionally exist as Vaults within a Vault. They have separate login paths and support creating and managing data isolated to their namespace.",
  "Maximum file size exceeded. File limit is 4MB.": "Maximum file size exceeded. File limit is 4MB.",
  "A PEM-encoded CA certificate file used to verify the Vault server's SSL certificate.": "A PEM-encoded CA certificate file used to verify the Vault server's SSL certificate.",
  "A PEM-encoded client certificate. This certificate is used for TLS communication with the Vault server.": "A PEM-encoded client certificate. This certificate is used for TLS communication with the Vault server.",
  "An unencrypted, PEM-encoded private key which corresponds to the matching client certificate provided with VAULT_CLIENT_CERT.": "An unencrypted, PEM-encoded private key which corresponds to the matching client certificate provided with VAULT_CLIENT_CERT.",
  "The name to use as the SNI host when OpenShift Container Storage connecting via TLS to the Vault server": "The name to use as the SNI host when OpenShift Container Storage connecting via TLS to the Vault server",
  "Key Management Service Advanced Settings": "Key Management Service Advanced Settings",
  "Backend Path": "Backend Path",
  "path/": "path/",
  "TLS Server Name": "TLS Server Name",
  "Vault Enterprise Namespace": "Vault Enterprise Namespace",
  "The name must be accurate and must match the service namespace": "The name must be accurate and must match the service namespace",
  "CA Certificate": "CA Certificate",
  "Upload a .PEM file here...": "Upload a .PEM file here...",
  "Client Certificate": "Client Certificate",
  "Client Private Key": "Client Private Key",
  "Attach OBC to a Deployment": "Attach OBC to a Deployment",
  "Deployment Name": "Deployment Name",
  "Attach": "Attach",
  "Create New Block Pool": "Create New Block Pool",
  "Delete Block Pool": "Delete Block Pool",
  "<0><0>{{poolName}}</0> cannot be deleted. When a pool is bounded to PVC it cannot be deleted. Please detach all the resources from storage class(es): <3>{{scNames}}</3>. </0>": "<0><0>{{poolName}}</0> cannot be deleted. When a pool is bounded to PVC it cannot be deleted. Please detach all the resources from storage class(es): <3>{{scNames}}</3>. </0>",
  "<0>Deleting <1>{{poolName}}</1> will remove all the saved data of this pool. Are you sure want to delete?</0>": "<0>Deleting <1>{{poolName}}</1> will remove all the saved data of this pool. Are you sure want to delete?</0>",
  "Block Pool Delete Modal": "Block Pool Delete Modal",
  "Try Again": "Try Again",
  "Finish": "Finish",
  "Go To Pvc List": "Go To Pvc List",
  "Edit Block Pool": "Edit Block Pool",
  "Block Pool Update Form": "Block Pool Update Form",
  "replacement disallowed: disk {{diskName}} is {{replacementStatus}}": "replacement disallowed: disk {{diskName}} is {{replacementStatus}}",
  "Disk Replacement": "Disk Replacement",
  "This action will start preparing the disk for replacement.": "This action will start preparing the disk for replacement.",
  "Data rebalancing is in progress": "Data rebalancing is in progress",
  "See data resiliency status": "See data resiliency status",
  "Are you sure you want to replace <1>{{diskName}}</1>?": "Are you sure you want to replace <1>{{diskName}}</1>?",
  "Replace": "Replace",
  "Create NamespaceStore ": "Create NamespaceStore ",
  "Represents an underlying storage to be used as read or write target for the data in the namespace buckets.": "Represents an underlying storage to be used as read or write target for the data in the namespace buckets.",
  "Provider {{provider}} | Region: {{region}}": "Provider {{provider}} | Region: {{region}}",
  "Create new NamespaceStore ": "Create new NamespaceStore ",
  "An error has occurred while fetching namespace stores": "An error has occurred while fetching namespace stores",
  "Select a namespace store": "Select a namespace store",
  "Namespace store name": "Namespace store name",
  "A unique name for the namespace store within the project": "A unique name for the namespace store within the project",
  "Namespace Store Table": "Namespace Store Table",
  "Where can I find google cloud credentials?": "Where can I find google cloud credentials?",
  "Service account keys are needed for Google Cloud Storage authentication. The keys can be found in the service accounts page in the GCP console.": "Service account keys are needed for Google Cloud Storage authentication. The keys can be found in the service accounts page in the GCP console.",
  "Learn more": "Learn more",
  "Upload a .json file with the service account keys provided by google cloud storage.": "Upload a .json file with the service account keys provided by google cloud storage.",
  "Secret Key": "Secret Key",
  "Upload JSON": "Upload JSON",
  "Uploaded File Name": "Uploaded File Name",
  "Upload File": "Upload File",
  "Browse": "Browse",
  "Switch to Secret": "Switch to Secret",
  "Select Secret": "Select Secret",
  "Switch to upload JSON": "Switch to upload JSON",
  "Cluster Metadata": "Cluster Metadata",
  "Target Bucket": "Target Bucket",
  "Number of Volumes": "Number of Volumes",
  "Volume Size": "Volume Size",
  "Target blob container": "Target blob container",
  "Target bucket": "Target bucket",
  "Account name": "Account name",
  "Access key": "Access key",
  "Account key": "Account key",
  "Secret key": "Secret key",
  "Region Dropdown": "Region Dropdown",
  "Endpoint": "Endpoint",
  "Endpoint Address": "Endpoint Address",
  "Secret": "Secret",
  "Switch to Credentials": "Switch to Credentials",
  "Access Key Field": "Access Key Field",
  "Secret Key Field": "Secret Key Field",
  " ObjectBucketClaim Name": " ObjectBucketClaim Name",
  "my-object-bucket": "my-object-bucket",
  "If not provided a generic name will be generated.": "If not provided a generic name will be generated.",
  "Defines the object-store service and the bucket provisioner.": "Defines the object-store service and the bucket provisioner.",
  "BucketClass": "BucketClass",
  "Select BucketClass": "Select BucketClass",
  "Create ObjectBucketClaim": "Create ObjectBucketClaim",
  "Edit YAML": "Edit YAML",
  "Attach to Deployment": "Attach to Deployment",
  "Object Bucket Claim Details": "Object Bucket Claim Details",
  "Object Bucket": "Object Bucket",
  "Namespace": "Namespace",
  "OBCTableHeader": "OBCTableHeader",
  "Object Bucket Claim Data": "Object Bucket Claim Data",
  "Hide Values": "Hide Values",
  "Reveal Values": "Reveal Values",
  "Data": "Data",
  "Create Object Bucket": "Create Object Bucket",
  "Object Bucket Name": "Object Bucket Name",
  "ob-name-help": "ob-name-help",
  "Object Bucket Details": "Object Bucket Details",
  "Object Bucket Claim": "Object Bucket Claim",
  "OBTableHeader": "OBTableHeader",
  "Selecting all nodes will use the available disks that match the selected filters on all nodes selected on previous step.": "Selecting all nodes will use the available disks that match the selected filters on all nodes selected on previous step.",
  "Minimum Node Requirement": "Minimum Node Requirement",
  "The OCS storage cluster require a minimum of 3 nodes for the intial deployment. Only {{nodes}} node match to the selected filters. Please adjust the filters to include more nodes.": "The OCS storage cluster require a minimum of 3 nodes for the intial deployment. Only {{nodes}} node match to the selected filters. Please adjust the filters to include more nodes.",
  "After the volume set and storage class are created you won't be able to go back to this step.": "After the volume set and storage class are created you won't be able to go back to this step.",
  "Note:": "Note:",
  "Create Storage Class": "Create Storage Class",
  "Yes": "Yes",
  "Are you sure you want to continue?": "Are you sure you want to continue?",
  "Node": "Node",
  "Selected Disks": "Selected Disks",
  "Disk List": "Disk List",
  "Selected Capacity": "Selected Capacity",
  "{{nodes, number}} Node": "{{nodes, number}} Node",
  "{{nodes, number}} Node_plural": "{{nodes, number}} Nodes",
  "{{disks, number}} Disk": "{{disks, number}} Disk",
  "{{disks, number}} Disk_plural": "{{disks, number}} Disks",
  "Selected versus Available Capacity": "Selected versus Available Capacity",
  "Out of {{capacity}}": "Out of {{capacity}}",
  "Selected Nodes": "Selected Nodes",
  "Review storage cluster": "Review storage cluster",
  "Storage and nodes": "Storage and nodes",
  "Arbiter zone:": "Arbiter zone:",
  "None": "None",
  "{{nodeCount, number}} node": "{{nodeCount, number}} node",
  "{{nodeCount, number}} node_plural": "{{nodeCount, number}} nodes",
  "selected based on the created storage class:": "selected based on the created storage class:",
  "Total CPU and memory of {{cpu, number}} CPU and {{memory}}": "Total CPU and memory of {{cpu, number}} CPU and {{memory}}",
  "{{zoneCount, number}} zone": "{{zoneCount, number}} zone",
  "{{zoneCount, number}} zone_plural": "{{zoneCount, number}} zones",
  "Configure": "Configure",
  "Enable Encryption": "Enable Encryption",
  "Connect to external key management service: {{name}}": "Connect to external key management service: {{name}}",
  "Encryption Level: {{level}}": "Encryption Level: {{level}}",
  "Using {{networkLabel}}": "Using {{networkLabel}}",
  "Next": "Next",
  "Back": "Back",
  "Discover Disks": "Discover Disks",
  "Storage and Nodes": "Storage and Nodes",
  "Review and Create": "Review and Create",
  "Can be used on any platform. It means that OCS uses attached disks, via Local Storage Operator. In this case, the infrastructure storage class is actually provided by LSO, on top of attached drives.": "Can be used on any platform. It means that OCS uses attached disks, via Local Storage Operator. In this case, the infrastructure storage class is actually provided by LSO, on top of attached drives.",
  "Before we can create a storage cluster, the local storage operator needs to be installed. When installation is finished come back to OpenShift Container Storage to create a storage cluster.<1><0>Install</0></1>": "Before we can create a storage cluster, the local storage operator needs to be installed. When installation is finished come back to OpenShift Container Storage to create a storage cluster.<1><0>Install</0></1>",
  "Role": "Role",
  "CPU": "CPU",
  "Memory": "Memory",
  "Zone": "Zone",
  "Node Table": "Node Table",
  "StorageCluster exists": "StorageCluster exists",
  "Back to operator page": "Back to operator page",
  "Go to cluster page": "Go to cluster page",
  "<0>A storage cluster <1>{{clusterName}}</1> already exists.<3>You cannot create another storage cluster.</3></0>": "<0>A storage cluster <1>{{clusterName}}</1> already exists.<3>You cannot create another storage cluster.</3></0>",
  "The uploaded file is not a valid JSON file": "The uploaded file is not a valid JSON file",
  "Connect to external cluster": "Connect to external cluster",
  "Download <1>{{SCRIPT_NAME}}</1> script and run on the RHCS cluster, then upload the results (JSON) in the External cluster metadata field.": "Download <1>{{SCRIPT_NAME}}</1> script and run on the RHCS cluster, then upload the results (JSON) in the External cluster metadata field.",
  "Download Script": "Download Script",
  "A bucket will be created to provide the OCS Service.": "A bucket will be created to provide the OCS Service.",
  "Create External Storage Cluster": "Create External Storage Cluster",
  "External cluster metadata": "External cluster metadata",
  "Upload JSON File": "Upload JSON File",
  "Upload Credentials file": "Upload Credentials file",
  "JSON data": "JSON data",
  "Create Button": "Create Button",
  "Create Storage Cluster": "Create Storage Cluster",
  "OCS runs as a cloud-native service for optimal integration with applications in need of storage and handles the scenes such as provisioning and management.": "OCS runs as a cloud-native service for optimal integration with applications in need of storage and handles the scenes such as provisioning and management.",
  "Enable arbiter": "Enable arbiter",
  "If not labeled, the selected nodes are labeled <1>{{label}}</1> to make them target hosts for OCS components.": "If not labeled, the selected nodes are labeled <1>{{label}}</1> to make them target hosts for OCS components.",
  "selected ({{cpu}} CPU and {{memory}} on ": "selected ({{cpu}} CPU and {{memory}} on ",
  "Enable taint nodes": "Enable taint nodes",
  "Selected nodes will be dedicated to OCS use only": "Selected nodes will be dedicated to OCS use only",
  "Stretch Cluster": "Stretch Cluster",
  "OpenShift Container Storage deployment in two data centers, with an arbiter node to settle quorum decisions.": "OpenShift Container Storage deployment in two data centers, with an arbiter node to settle quorum decisions.",
  "Enable Arbiter": "Enable Arbiter",
  "To support high availability when two data centers can be used, enable arbiter to get the valid quorum between two data centers.": "To support high availability when two data centers can be used, enable arbiter to get the valid quorum between two data centers.",
  "Arbiter minimum requirements": "Arbiter minimum requirements",
  "Select an arbiter zone": "Select an arbiter zone",
  "Arbiter zone selection": "Arbiter zone selection",
  "Storage class encryption": "Storage class encryption",
  "The storage cluster encryption level can be set to include all components under the cluster (including storage class and PVs) or to include only storage class encryption. PV encryption can use an auth token that will be used with the KMS configuration to allow multi-tenancy.": "The storage cluster encryption level can be set to include all components under the cluster (including storage class and PVs) or to include only storage class encryption. PV encryption can use an auth token that will be used with the KMS configuration to allow multi-tenancy.",
  "Data encryption for block and file storage. MultiCloud Object Gateway is always encrypted.": "Data encryption for block and file storage. MultiCloud Object Gateway is always encrypted.",
  "Encryption level": "Encryption level",
  "Cluster-wide encryption": "Cluster-wide encryption",
  "Encryption for the entire cluster (block and file)": "Encryption for the entire cluster (block and file)",
  "An encryption key will be generated for each persistent volume (block) created using an encryption enabled storageclass.": "An encryption key will be generated for each persistent volume (block) created using an encryption enabled storageclass.",
  "Connection settings": "Connection settings",
  "Connect to an external key management service": "Connect to an external key management service",
  "Network": "Network",
  "The default SDN networking uses a single network for all data operations such read/write and also for control plane, such as data replication. Multus allows a network separation between the data operations and the control plane operations.": "The default SDN networking uses a single network for all data operations such read/write and also for control plane, such as data replication. Multus allows a network separation between the data operations and the control plane operations.",
  "Default (SDN)": "Default (SDN)",
  "Custom (Multus)": "Custom (Multus)",
  "Public Network Interface": "Public Network Interface",
  "Select a network": "Select a network",
  "Cluster Network Interface": "Cluster Network Interface",
  "Capacity and nodes": "Capacity and nodes",
  "Requested Cluster Capacity:": "Requested Cluster Capacity:",
  "Storage Class:": "Storage Class:",
  "Select Capacity": "Select Capacity",
  "Requested Capacity": "Requested Capacity",
  "Select Nodes": "Select Nodes",
  "Select at least 3 nodes preferably in 3 different zones. It is recommended to start with at least 14 CPUs and 34 GiB per node.": "Select at least 3 nodes preferably in 3 different zones. It is recommended to start with at least 14 CPUs and 34 GiB per node.",
  "Search by node name...": "Search by node name...",
  "Search by node label...": "Search by node label...",
  "create internal mode storage cluster wizard": "create internal mode storage cluster wizard",
  "Select capacity and nodes": "Select capacity and nodes",
  "Review and create": "Review and create",
  "Can be used on any platform, except bare metal. It means that OCS uses an infrastructure storage class, provided by the hosting platform. For example, gp2 on AWS, thin on VMWare, etc.": "Can be used on any platform, except bare metal. It means that OCS uses an infrastructure storage class, provided by the hosting platform. For example, gp2 on AWS, thin on VMWare, etc.",
  "{{title}} steps": "{{title}} steps",
  "{{title}} content": "{{title}} content",
  "{{availableCapacity}} /  {{replica}} replicas": "{{availableCapacity}} /  {{replica}} replicas",
  "{{capacityText}}:": "{{capacityText}}:",
  "This is an Advanced subscription feature. It requires Advanced Edition subscription. Please contact the account team for more information.": "This is an Advanced subscription feature. It requires Advanced Edition subscription. Please contact the account team for more information.",
  "Advanced Subscription": "Advanced Subscription",
  "no compression": "no compression",
  "with compression": "with compression",
  "Replica {{poolSize}} {{compressionText}}": "Replica {{poolSize}} {{compressionText}}",
  "Create New Pool": "Create New Pool",
  "Storage Pool": "Storage Pool",
  "Select a Pool": "Select a Pool",
  "Storage pool into which volume data shall be stored": "Storage pool into which volume data shall be stored",
  "Error retrieving Parameters": "Error retrieving Parameters",
  "my-storage-pool": "my-storage-pool",
  "Connection details": "Connection details",
  "Change connection details": "Change connection details",
  "Vault Enterprise Namespace:": "Vault Enterprise Namespace:",
  "Key management service name:": "Key management service name:",
  "Provider:": "Provider:",
  "Address and Port:": "Address and Port:",
  "CA certificate:": "CA certificate:",
  "Provided": "Provided",
  "KMS service {{value}} already exist": "KMS service {{value}} already exist",
  "An encryption key will be generated for each persistent volume created using this storageclass.": "An encryption key will be generated for each persistent volume created using this storageclass.",
  "PV expansion operation is not supported for encrypted PVs.": "PV expansion operation is not supported for encrypted PVs.",
  "The last saved values will be updated": "The last saved values will be updated",
  "Enable Thick Provisioning": "Enable Thick Provisioning",
  "By enabling thick-provisioning, volumes will allocate the requested capacity upon volume creation. Volume creation to be slower when thick-provisioning is enabled.": "By enabling thick-provisioning, volumes will allocate the requested capacity upon volume creation. Volume creation to be slower when thick-provisioning is enabled.",
  "Storage status represents the health status of the Openshift Container Storage's storage cluster.": "Storage status represents the health status of the Openshift Container Storage's storage cluster.",
  "Health": "Health",
  "Openshift Container Storage": "Openshift Container Storage",
  "Standard": "Standard",
  "Data will be ingested by Multi-cloud object gateway, deduped, compressed and encrypted. The encrypted chunks would be saved on the selected backing stores. Best used when the applications would always use the OpenShift Container Storage endpoints to access the data.": "Data will be ingested by Multi-cloud object gateway, deduped, compressed and encrypted. The encrypted chunks would be saved on the selected backing stores. Best used when the applications would always use the OpenShift Container Storage endpoints to access the data.",
  "Data will be stored as is(no dedupe, compression, encryption) on the namespace stores. Namespace buckets allow for connecting to existing data and serving from them. Best used for existing data or when other applications (and native cloud services) need to access the data from outside the OpenShift Container Storage.": "Data will be stored as is(no dedupe, compression, encryption) on the namespace stores. Namespace buckets allow for connecting to existing data and serving from them. Best used for existing data or when other applications (and native cloud services) need to access the data from outside the OpenShift Container Storage.",
  "Single namespace-store": "Single namespace-store",
  "Multi namespace-stores": "Multi namespace-stores",
  "The namespace bucket will serve reads from several selected backing stores, creating a virtual namespace on top of them and will write to one of those as its chosen write target": "The namespace bucket will serve reads from several selected backing stores, creating a virtual namespace on top of them and will write to one of those as its chosen write target",
  "Cache namespace-store": "Cache namespace-store",
  "The caching bucket will serve data from a large raw data out of a local caching tiering.": "The caching bucket will serve data from a large raw data out of a local caching tiering.",
  "Logical used capacity per account": "Logical used capacity per account",
  "Egress Per Provider": "Egress Per Provider",
  "I/O Operations count": "I/O Operations count",
  "The infrastructure storage class used by OpenShift Container Storage to write its data and metadata.": "The infrastructure storage class used by OpenShift Container Storage to write its data and metadata.",
  "Infrastructure storage class created by Local Storage Operator and used by OpenShift Container Storage to write its data and metadata.": "Infrastructure storage class created by Local Storage Operator and used by OpenShift Container Storage to write its data and metadata.",
  "The amount of capacity that would be dynamically allocated on the infrastructure storage class.": "The amount of capacity that would be dynamically allocated on the infrastructure storage class.",
  "If you wish to use the Arbiter stretch cluster, a minimum of 4 nodes (2 different zones, 2 nodes per zone) and 1 additional zone with 1 node is required. All nodes must be pre-labeled with zones in order to be validated on cluster creation.": "If you wish to use the Arbiter stretch cluster, a minimum of 4 nodes (2 different zones, 2 nodes per zone) and 1 additional zone with 1 node is required. All nodes must be pre-labeled with zones in order to be validated on cluster creation.",
  "Selected nodes are based on the selected storage class. The selected nodes will preferably be in 3 different zones with a recommended requirement of 14 CPUs and 34 GiB per node.": "Selected nodes are based on the selected storage class. The selected nodes will preferably be in 3 different zones with a recommended requirement of 14 CPUs and 34 GiB per node.",
  "Selected nodes are based on the selected storage class. 4 nodes in 2 different zones will be selected with a recommended requirement of 14 CPU and 34 GiB RAM per node.": "Selected nodes are based on the selected storage class. 4 nodes in 2 different zones will be selected with a recommended requirement of 14 CPU and 34 GiB RAM per node.",
  "Block and File": "Block and File",
  "Storage": "Storage",
  "Disks": "Disks",
  "Edit Bucket Class Resources": "Edit Bucket Class Resources",
  "Loading...": "Loading...",
  "Pool {name} creation in progress": "Pool {name} creation in progress",
  "Pool {name} was successfully created": "Pool {name} was successfully created",
  "An error occurred Pool {name} was not created": "An error occurred Pool {name} was not created",
  "Pool {name} creation timed out. Please check if ocs-operator and rook operator are running": "Pool {name} creation timed out. Please check if ocs-operator and rook operator are running",
  "The creation of an OCS storage cluster is still in progress or has failed. Please try again after the storage cluster is ready to use.": "The creation of an OCS storage cluster is still in progress or has failed. Please try again after the storage cluster is ready to use.",
  "Pool management tasks are not supported for default pool and Openshift Container Storage's  external mode.": "Pool management tasks are not supported for default pool and Openshift Container Storage's  external mode.",
  "hr": "hr",
  "min": "min",
  "A minimal cluster deployment will be performed.": "A minimal cluster deployment will be performed.",
  "The selected nodes do not match the OCS storage cluster requirement of an aggregated 30 CPUs and 72 GiB of RAM. If the selection cannot be modified a minimal cluster will be deployed.": "The selected nodes do not match the OCS storage cluster requirement of an aggregated 30 CPUs and 72 GiB of RAM. If the selection cannot be modified a minimal cluster will be deployed.",
  "Back to nodes selection": "Back to nodes selection",
  "Select a storage class to continue": "Select a storage class to continue",
  "This is a required field. The Storage Class will be used to request storage from the underlying infrastructure to create the backing persistent volumes that will be used to provide the OpenShift Container Storage (OCS) service.": "This is a required field. The Storage Class will be used to request storage from the underlying infrastructure to create the backing persistent volumes that will be used to provide the OpenShift Container Storage (OCS) service.",
  "Create new storage class": "Create new storage class",
  "All required fields are not set": "All required fields are not set",
  "In order to create the storage cluster you must set the storage class, select at least 3 nodes (preferably in 3 different zones) and meet the minimum or recommended requirement": "In order to create the storage cluster you must set the storage class, select at least 3 nodes (preferably in 3 different zones) and meet the minimum or recommended requirement",
  "The OCS Storage cluster require a minimum of 3 nodes for the initial deployment. Please choose a different storage class or go to create a new volume set that matches the minimum node requirement.": "The OCS Storage cluster require a minimum of 3 nodes for the initial deployment. Please choose a different storage class or go to create a new volume set that matches the minimum node requirement.",
  "Create new volume set instance": "Create new volume set instance",
  "Select at least 1 encryption level or disable encryption.": "Select at least 1 encryption level or disable encryption.",
  "Fill out the details in order to connect to key management system": "Fill out the details in order to connect to key management system",
  "This is a required field.": "This is a required field.",
  "Public Network Attachment Definition cannot be empty": "Public Network Attachment Definition cannot be empty",
  "To use Multus networking the public Network Attachment Definition must be selected.": "To use Multus networking the public Network Attachment Definition must be selected.",
  "The number of selected zones is less than the minimum requirement of 3. If not modified a host-based failure domain deployment will be enforced.": "The number of selected zones is less than the minimum requirement of 3. If not modified a host-based failure domain deployment will be enforced.",
  "When the nodes in the selected storage class are spread across fewer than 3 availability zones, the storage cluster will be deployed with the host based failure domain.": "When the nodes in the selected storage class are spread across fewer than 3 availability zones, the storage cluster will be deployed with the host based failure domain.",
  "Cluster-Wide and Storage Class": "Cluster-Wide and Storage Class",
  "Cluster-Wide": "Cluster-Wide",
  "and": "and",
  "Select at least 2 Backing Store resources": "Select at least 2 Backing Store resources",
  "Select at least 1 Backing Store resource": "Select at least 1 Backing Store resource",
  "x {{replica}} replicas = {{osdSize, number}} TiB": "x {{replica}} replicas = {{osdSize, number}} TiB",
  "SmallScale": "SmallScale",
  "0.5 TiB": "0.5 TiB",
  "2 TiB": "2 TiB",
  "LargeScale": "LargeScale",
  "4 TiB": "4 TiB",
  "{{osdSize, number}} TiB": "{{osdSize, number}} TiB"
}